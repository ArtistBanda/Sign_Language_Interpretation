{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7fUvzy_ZtTEd"
   },
   "source": [
    "# Download Training Data\n",
    "\n",
    "Set up kaggle api to install data\n",
    "\n",
    "For Ubuntu 18.04\n",
    "\n",
    "```console\n",
    "$ pip install kaggle\n",
    "\n",
    "```\n",
    "\n",
    "Download kaggle.json from your kaggle profile and copy it to ~/.kaggle\n",
    "\n",
    "$ mkdir ~/.kaggle\n",
    "\n",
    "$ cp ~/Downloads/kaggle.json ~/.kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘/home/artistbanda/.kaggle’: File exists\n",
      "cp: cannot stat 'kaggle.json': No such file or directory\n",
      "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /home/artistbanda/.kaggle/kaggle.json'\n",
      "Downloading asl-alphabet.zip to /home/artistbanda/Documents/Projects/Sign_Language_Interpretation/v2\n",
      "  1%|▏                                     | 6.00M/1.03G [00:04<12:28, 1.46MB/s]^C\n",
      "  1%|▏                                     | 6.00M/1.03G [00:04<13:18, 1.37MB/s]\n",
      "User cancelled operation\n",
      "Archive:  asl-alphabet.zip\n",
      "  End-of-central-directory signature not found.  Either this file is not\n",
      "  a zipfile, or it constitutes one disk of a multi-part archive.  In the\n",
      "  latter case the central directory and zipfile comment will be found on\n",
      "  the last disk(s) of this archive.\n",
      "unzip:  cannot find zipfile directory in one of asl-alphabet or\n",
      "        asl-alphabet.zip, and cannot find asl-alphabet.ZIP, period.\n"
     ]
    }
   ],
   "source": [
    "! kaggle datasets download -d grassknoted/asl-alphabet\n",
    "! unzip asl-alphabet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0LNn-RJnthsu"
   },
   "source": [
    "# Importing all the pre-requisite libraries\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "OhrUmXPAWANT",
    "outputId": "86c9aba4-d548-4b17-ffb8-4193ff6b609c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.resnet50 import ResNet50\n",
    "from sklearn import metrics\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import keras\n",
    "import cv2\n",
    "import shutil\n",
    "import tensorflow as tf\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.metrics import categorical_accuracy\n",
    "from keras.utils import plot_model, to_categorical\n",
    "from keras.models import Model,load_model, Sequential\n",
    "from keras.models import load_model\n",
    "from keras.layers import Input, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D\n",
    "from keras.layers import AveragePooling2D, MaxPooling2D, Dropout, GlobalMaxPooling2D, GlobalAveragePooling2D\n",
    "from keras import regularizers\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ahj6Cniit4nv"
   },
   "source": [
    "# Neural Network Modelling\n",
    "Using **Resnet50** as the base model for the neural network framework.\n",
    "Then adding 3 fully connected layers of 1024 neurons with *relu* activation function and adding the last output layer using *softmax* activation with 29 nuerons.\n",
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 405
    },
    "colab_type": "code",
    "id": "XVcmh49LWA2C",
    "outputId": "16234801-e771-478e-f977-de63c5e36da5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0826 15:52:07.393628 140488690247552 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0826 15:52:07.432772 140488690247552 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0826 15:52:07.441434 140488690247552 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4185: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
      "\n",
      "W0826 15:52:07.477871 140488690247552 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W0826 15:52:07.479602 140488690247552 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "W0826 15:52:10.352840 140488690247552 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "W0826 15:52:10.420626 140488690247552 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
      "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.2/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "94658560/94653016 [==============================] - 3s 0us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0826 15:52:21.383858 140488690247552 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "img_height,img_width=(200,200)\n",
    "base_model = ResNet50(weights= 'imagenet', include_top=False, input_shape= (200,200,3))\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "num_classes=29\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "# x = Dropout(0.3)(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "# x = Dropout(0.3)(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "# x = Dropout(0.3)(x)\n",
    "predictions = Dense(num_classes, activation= 'softmax')(x)\n",
    "model = Model(inputs = base_model.input, outputs = predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P0P-dmo6vC3G"
   },
   "source": [
    "# Learning Algorithm\n",
    "Using adam optimizer with loss as categorical crossentropy and printing out accuracy as metrics while learning.\n",
    "\n",
    "*Define the directory if you are running notebook on local machine*\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "## Train 1\n",
    "First the model is trained on the Resnet for 10 epochs and batch size of 32\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uIlYyN65nxkx"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "EPOCHS = 10\n",
    "BS = 32\n",
    "aug = ImageDataGenerator(rotation_range=5, zoom_range=0.2, rescale=1./255,\n",
    "                         width_shift_range=0.2, height_shift_range=0.2,\n",
    "                         shear_range=0.18,\n",
    "                         horizontal_flip=False, fill_mode=\"nearest\")\n",
    "\n",
    "#directory for image as data\n",
    "directory = \"/content/asl_alphabet_train\"\n",
    "\n",
    "image_generator = aug.flow_from_directory(directory, target_size=(200, 200), \n",
    "                    class_mode='categorical',batch_size=32)\n",
    "\n",
    "H = model.fit_generator(image_generator,steps_per_epoch=2718, epochs=EPOCHS).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b5Tpj3W-0L5A"
   },
   "outputs": [],
   "source": [
    "for layer in model.layers:\n",
    "    layer.trainable = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vSlkYMI80q9H"
   },
   "source": [
    "## Train 2\n",
    "Then it is trained on the 3 additional fully connected layers for 2 epochs and batch size of 32\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BDQmcSewnzck"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "EPOCHS = 2\n",
    "BS = 32\n",
    "aug = ImageDataGenerator(rotation_range=5, zoom_range=0.2, rescale=1./255,\n",
    "                         width_shift_range=0.2, height_shift_range=0.2,\n",
    "                         shear_range=0.18,\n",
    "                         horizontal_flip=False, fill_mode=\"nearest\")\n",
    "\n",
    "#directory for image as data\n",
    "directory = \"/content/asl_alphabet_train\"\n",
    "\n",
    "image_generator = aug.flow_from_directory(directory, target_size=(200, 200), \n",
    "                    class_mode='categorical',batch_size=32)\n",
    "\n",
    "H2 = model.fit_generator(image_generator,steps_per_epoch=2718, epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SrWnFI2H0-Mo"
   },
   "source": [
    "## Final steps\n",
    "Saving the model and printing history of first and second train\n",
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zOzgMXx-063e"
   },
   "outputs": [],
   "source": [
    "model.save(\"./resnet1.h5\")\n",
    "\n",
    "H.history\n",
    "\n",
    "H2.history"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Training_Model.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
